<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Tidy data, the tidyverse and tidying data</title>
    <meta charset="utf-8" />
    <meta name="author" content="Emma Rand" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/shareon/shareon.min.css" rel="stylesheet" />
    <script src="libs/shareon/shareon.min.js"></script>
    <link href="libs/xaringanExtra-shareagain/shareagain.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-shareagain/shareagain.js"></script>
    <link href="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link href="libs/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <link rel="stylesheet" href="../css_files/emma.css" type="text/css" />
    <link rel="stylesheet" href="../css_files/emma-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Tidy data, the tidyverse and tidying data
## Data Science option of BIO00058M Data Analysis.
### Emma Rand
### University of York, UK

---



<style>.shareagain-bar {
--shareagain-foreground: rgb(255, 255, 255);
--shareagain-background: rgba(0, 0, 0, 0.5);
}</style>






&lt;style&gt;
div.blue { background-color:#b0cdef; border-radius: 5px; padding: 20px;}
div.grey { background-color:#d3d3d3; border-radius: 0px; padding: 0px;}
&lt;/style&gt;

# Outline

The aim of this section is to strength your understanding of the tidyverse &lt;a name=cite-Wickham2019-ml&gt;&lt;/a&gt;([Wickham Averick, et al., 2019](#bib-Wickham2019-ml)) including the pipe, `%&gt;%`  and some commonly applied data tidying operations.

It includes a case study which demonstrates how to problem solve your way to a solution using a one-step-at-a-time approach.

---
# Outline

You should be able to code along with the examples. When you see the film clapper it is ..

ðŸŽ¬ .. an instruction to do something!!


--

ðŸŽ¬ Go through the workflow for creating a [new RStudio Project](https://3mmarand.github.io/BIO00058M-Data-science-2020/workshops/01_project_organisation.html#Task_1_New_RStudio_Project) with the **`usethis`** &lt;a name=cite-usethis&gt;&lt;/a&gt;([Wickham and Bryan, 2021](#bib-usethis)). I suggested including directories `R/`, `data-raw/`, and `data-processed/` 

---
class: inverse

#  What is tidy data?


---
# What is tidy data?

Tidy data adhere to a consistent structure which makes it easier to manipulate, model and visualize them. The structure is defined by:  

1. Each variable has its own column.  
2. Each observation has its own row.  
3. Each value has its own cell.  

--

Closely allied to the relational algebra of relational databases &lt;a name=cite-Codd1990-th&gt;&lt;/a&gt;([Codd, 1990](#bib-Codd1990-th)).  
Underlies the enforced rectangular formatting in SPSS, STATA and R's dataframe/tibble.  
The term 'tidy data' was popularised by &lt;a name=cite-Wickham2014-nl&gt;&lt;/a&gt;[Wickham (2014)](#bib-Wickham2014-nl).   

Note: There may be more than one potential tidy structure.

---
# Tidy format



Suppose we had just 3 individuals in each of two populations:

.pull-left[
NOT TIDY!
two observations per row
column names are not variables
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; A &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; B &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 12.4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 12.6 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 11.2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 11.3 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 11.6 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 12.1 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]


.pull-right[

TIDY!
one observation per row
column names are the two variables
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; population &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; distance &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; A &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 12.4 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; A &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 11.2 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; A &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 11.6 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; B &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 12.6 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; B &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 11.3 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; B &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 12.1 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]


---
class: inverse

#  Tidyverse


---
# Tidyverse

The [tidyverse](https://www.tidyverse.org/)   is both a paradigm for coding in R and a metapackage (a collection of packages).

Contributors describe it as "an opinionated" collection of R packages designed for data science. 

--

The key feature is that all **`tidyverse`** packages share an underlying design philosophy, grammar, and data structures.  

This means:
-  they work well together
-  learning a new tidyverse packages is quick
-  data work is more efficient.

---
# Tidyverse

**`tidyverse`** packages have a reputation for making code which is easy for humans to read and to write, and for enabling tools to be connected into reproducible workflows.

The R Views [article by Joe Rickert](https://rviews.rstudio.com/2017/06/08/what-is-the-tidyverse/) gives a good overview.

---
# Tidyverse

The are many other extremely useful packages that are not part of the tidyverse but which also use a common design across packages. 

An example is the [Bioconductor Project](https://www.bioconductor.org/).

--

However, Bioconductor packages that take a tidyverse approach are beginning to accumulate. For example:

* **`tidybulk`** &lt;a name=cite-R-tidybulk&gt;&lt;/a&gt;([Mangiola, 2020](#bib-R-tidybulk)). See also .font70[https://stemangiola.github.io/rpharma2020_tidytranscriptomics/articles/tidytranscriptomics.html]
* **`biobroom`** &lt;a name=cite-R-biobroom&gt;&lt;/a&gt;([Bass Robinson, et al., 2020](#bib-R-biobroom))



---
# Tidyverse

You should already have `tidyverse` installed. Packages need installing only once (unless you wish to update them) but must be loaded every session.

ðŸŽ¬ Load the core tidyverse packages with:

```r
library(tidyverse)
```

--
[Core packages](https://www.tidyverse.org/packages/) are: **`ggplot2`**, **`dplyr`**, **`tidyr`**, **`readr`**, **`purr`**, **`tibble`**, **`stringr`** and **`forcats`**

--

Actually, **`ggplot2`** predates the tidyverse which is why it uses `+` to link functions together. It does use the same sort of grammar and works very well within the tidyverse.

---
# Tidyverse

The tidyverse also includes many other packages with more specialised usage. They are not loaded automatically with `library(tidyverse)`and need their own `library()` calls. 

--

Examples are `readxl`, `haven`, `rvest` and `lubridate.`


---
class: inverse

#  The pipe %&gt;%

---
# The pipe %&gt;%

The pipe `%&gt;%` operator from the `magrittr` package  is loaded with core tidyverse. 


It is the feature that allows us to connect tools together in a readable way.

It can improve code readability by:

--

* structuring sequences of data operations left-to-right or top-to-bottom (as opposed to from the inside and out),

--

* minimizing the need for intermediates, 

--

* making it easy to add steps anywhere in the sequence of operations.

---
# The pipe %&gt;%

The pipe means that instead of using: 

```r
function(object) 
```

We can use 

```r
object %&gt;% function()
```

--

This is useful when you have multiple functions to apply.
---
# The pipe %&gt;%

Instead of:


```r
function2(function1(object)) 
```

We can use 

```r
object %&gt;% function1()  %&gt;% function2()
```

---
# The pipe %&gt;%

As a simple example, suppose we want to apply a log-squareroot transformation&lt;sup&gt;1&lt;/sup&gt; to some proportion data. 

.font70[
.footnote[1. a transformation commonly applied to proportion data to make it less platykurtic `\(x^{t} = log(\sqrt{x})\)`
]
]

--

ðŸŽ¬ Generate a random sample of ten proportions to work with:


```r
nums &lt;- sample((1:100)/100, size = 10, replace = FALSE)
```

--

Two ways we *could* apply the log-squareroot transformation are to:

1. nest the squareroot and log functions  
2. create intermediate variables  

---
# The pipe %&gt;%

ðŸŽ¬ Nest the `sqrt()` and `log()` functions:


```r
tnums &lt;- log(sqrt(nums))
```

--

Code must read from inside to outside. 

Increasingly difficult to read as number of functions increases. 

Also makes simple debugging harder.

---
# The pipe %&gt;%

ðŸŽ¬ Create intermediate variables:


```r
sqrtnums &lt;- sqrt(nums)
tnums &lt;- log(sqrtnums)
```

--

Easier to read than nesting.

But you have extra variables you don't need and which become increasingly difficult to name appropriately creating code and workspace clutter.

---
# The pipe %&gt;%

Using the pipe avoids these by taking the output of one operation as the input of the next. 

The pipe has long been used by Unix operating systems (where the pipe operator is `|`). 

The R pipe operator is `%&gt;%` &lt;sup&gt;1&lt;/sup&gt;


.font70[
.footnote[1. a pipe recently became available in base R too (with R version 4.1.0). Here the operator is `|&gt;`
]
]

--

ðŸŽ¬ The keyboard short cut is ctrl-shift-M.

---
# The pipe %&gt;%

ðŸŽ¬ Use pipes to code the functions in sequence:

```r
tnums &lt;- nums %&gt;% 
  sqrt() %&gt;% 
  log()
```

--

This can be read as: take `nums` *and then* squareroot it *and then* log it.

---
# The pipe %&gt;%

More explicitly, this is:


```r
tnums &lt;- nums %&gt;% 
  sqrt(.) %&gt;% 
  log(.)
```

Where `.` stands for the object being passed in. 

In most cases, you don't need to include the `.`.

Occasionally you do have to, for example when arguments are optional or there is ambiguity over which argument is meant.

---
class: inverse

#  Data tidying tasks

---
# Data tidying tasks

Tidying data includes reshaping it in to 'tidy' format but also other tasks such as:

* renaming variables for consistency  
* recoding variables  
* cleaning content for consistency with respect to valid values, missing values and NA  

--

ðŸ‘€ Key point!

* Keep the raw data exactly as it came to you and do not alter/edit.
* Script and document all tidying tasks.

---
class: inverse
# Converting "wide" to "long"

---
# Converting "wide" to "long"

Data commonly need to be reshaped from a format with more than one observation per row.

--

The data given in [biomass.txt](../data-raw/biomass.txt) are taken from an experiment in which the insect pest biomass (g) was measured on plots sprayed  with water (control) or one of five different insecticides. 

Also in the data file are variables indicating the replicate number and the identity of the tray in which the plant was grown.

---
# Converting "wide" to "long"

ðŸŽ¬ Save a copy of this file to your `data-raw` folder and read it in.


```r
file &lt;- "../data-raw/biomass.txt"
biomass &lt;- read_table(file)
```

`read_table()` is a function from the tidyverse's **`readr`** package. It works a lot like base R's `read.table()` but with some useful defaults (e.g., is header assumed) and extra functionality (e.g.,it's faster).

tidyverse import functions treat strings as character variables by default, not factors. Until R 4.x, `read.table()` turned strings into factors. This used to be an important reason for me to use `read_table()`.

Whilst analysis and visualisation often require factor variables, any processing of strings is made much easier if they are characters.

---
# Converting "wide" to "long"

ðŸŽ¬ View the dataframe.

.scroll-output-height[
.code70[

```
## # A tibble: 10 x 7
##    WaterControl     A     B     C     D     E rep_tray
##           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   
##  1         350. 159.  150.   80.0  267.  350. 1_x     
##  2         324. 146.  154.  266.   110.  320. 2_x     
##  3         359. 116.   69.5 161.   221.  359. 3_x     
##  4         255. 135.  151.  161.   160.  255. 4_y     
##  5         208. 137.  213.   51.2  198.  208. 5_y     
##  6         326.  81.8 144.  184.   270.  326. 6_y     
##  7         295. 116.  150.  176.   224.  295. 7_z     
##  8         285. 114.  134.  136.   141.  285. 8_z     
##  9         383. 155.  153.  159.   290.  383. 9_z     
## 10         279. 144.  198.  126.   189.  279. 10_z
```
]
]


A tibble is the tidyverse's dataframe. In fact, tibbles are dataframes as well as tibbles.

---
# Converting "wide" to "long"

These data are in "wide" format and can be converting to "long" format using the `tidyr` package function `pivot_longer()`. 

--

`pivot_longer()` collects the values from specified columns (`cols`) into a single column (`values_to`) and creates a column to indicate the group (`names_to`). 

--

We want to gather the first 6 columns but the `rep_tray` column contents should be repeated.


---
# Converting "wide" to "long"

ðŸŽ¬ Gather all the columns of biomass except `rep_tray`:


```r
biomass2 &lt;- biomass %&gt;% 
  pivot_longer(names_to = "spray", 
         values_to = "mass",
         cols = -rep_tray)
```

The values will be in a column called `mass`, the treatments in a column called `spray`.

---
# Converting "wide" to "long"

ðŸŽ¬ View the dataframe.

.scroll-output-height[
.code70[

```
## # A tibble: 60 x 3
##    rep_tray spray         mass
##    &lt;chr&gt;    &lt;chr&gt;        &lt;dbl&gt;
##  1 1_x      WaterControl 350. 
##  2 1_x      A            159. 
##  3 1_x      B            150. 
##  4 1_x      C             80.0
##  5 1_x      D            267. 
##  6 1_x      E            350. 
##  7 2_x      WaterControl 324. 
##  8 2_x      A            146. 
##  9 2_x      B            154. 
## 10 2_x      C            266. 
## # ... with 50 more rows
```
]
]

---
# Converting "wide" to "long"

&lt;span style=" font-weight: bold;    color: #fdf9f6 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #25496b !important;" &gt;Extra exercise:&lt;/span&gt; Write this dataframe to file to your `processed_data` folder. This was covered in the [Project Organisation workshop](https://3mmarand.github.io/BIO00058M-Data-science-2020/workshops/01_project_organisation.html)




See the result: [biomass2-tidyverse.txt](../data-processed/biomass2-tidyverse.txt)

---
class: inverse

# Splitting column contents
---
# Splitting column contents

We sometimes have single columns which contain more than one type of encoded information. 

--

For example, if a column contains a full species name you may wish to separate the genus and species into separate columns. This allows you to perform a by-genus analysis.

--

Another example arises when you read in multiple files with names that encode a date, experiment or treatment. We  can add the file name to a column and then split the name into columns for the date, experiment or treatment.

---
# Splitting column contents

For the `biomass2` data we might wish to separate the replicate number from the tray identity and put them in two separate columns. 

--


We can do this with a 'regular expression' or [regex](https://en.wikipedia.org/wiki/Regular_expression). A regex defines a pattern for matching text. 

--

It's a big topic and there are many tutorials. I remember a few bits and google "how to match ... regex". 

[A quick reference](https://www.rexegg.com/regex-quickstart.html)

---
# Splitting column contents

The `extract()` function from the `tidyr` helps us achieve this.

We give:
-  the names of the new columns we want to create
-  the patterns matching the part of the `rep_tray` value we want to go in each column.

---
# Splitting column contents

ðŸŽ¬ Extract parts of `rep_tray` and put in new columns `replicate_number`, `tray_id`:


```r
biomass3 &lt;- biomass2 %&gt;% 
  extract(rep_tray, 
          c("replicate_number", "tray_id"),
          "([0-9]{1,2})\\_([a-z])")
```

--
.font80[
-  The patterns to save into columns are inside `( )`.  
-  The pattern going into `replicate_number`, `[0-9]{1,2}`, means 1 or 2 numbers.  
-  The pattern going into `tray_id`, `[a-z]` means one lowercase letter.
-  the bit between the two `( )`, `\_` is a pattern that matches what is in `rep_tray` but is not to be saved. 
]
 

---
class: inverse
# Case study

---
# Case study

## Overivew

You will now work through an example of some real data from [The Genever Group](https://www.geneverlab.info/). The arrangement and format of these data are typical of many protein and gene expression datasets so the processing is representative of that needed in a variety of situations.

--

The data are mass spectrometry data of the soluble protein fraction from five immortalised mesenchymal stromal cell (MSC) lines. 

The data are normalised protein abundances. Each row is a protein.

---
# Case study

ðŸŽ¬ Save a copy of [Y101_Y102_Y201_Y202_Y101-5.csv](../data-raw/Y101_Y102_Y201_Y202_Y101-5.csv) file to your `data-raw` folder.

ðŸŽ¬ You may wish to view it in excel while reading the information on the next page.

---
# Case study

**Data description**

The cells lines are Y101, Y102, Y201, Y202 and Y101.5 and there are three replicates for each cell line arranged in columns. Also in the file are columns for:
.font70[
-  the protein accession
-  the number of peptides used to identify the protein
-  the number of unique peptides used to identify the protein
-  a measure of confidence in that identification
-  the maximum fold change between the mean abundances of two cell lines (i.e., highest mean / lowest mean)
-  a *p* value for a comparison test between the highest mean and lowest mean
-  a *q* value (corrected *p* value) 
-  a measure of the power of that test
-  the cell line with the highest mean
-  the cell line with the lowest mean
-  the protein mass
-  whether at least two peptides were detected for a protein.
]
---
# Case study

**Data Import**

Column names are spread over three rows but are primarily in the third row.

--

We can read in from the third row by skipping the first two. We can also use the `clean()` function from the **`janitor`** package to improve the column names.

---
# Case study

**Data Import**

ðŸŽ¬ Read in the file using `read_csv()` from the **`tidyverse`**'s **`readr`** package.

```r
# define file name
filesol &lt;- "../data-raw/Y101_Y102_Y201_Y202_Y101-5.csv"

# skip first two lines
sol &lt;- read_csv(filesol, skip = 2) %&gt;% 
  janitor::clean_names()
```

---
# Case study

**Data Import**

ðŸ‘€ the `::` notation gives you access to a package's functions without first using the `library()` command. 

This is useful when you only want to use one function from a package, or when you need to specify which package the function is in. 

---
# Case study

**Filtering rows**

The cells were grown on bovine serum and any bovine proteins need to be filtered out.

--

If a protein identify has been determined by fewer than two peptides we are not confident in that identification. Such proteins should also be filtered out. This is common practice for  proteomic data. 

---
# Case study

**Filtering rows**

**`dplyr`** (yep, a tidyverse package) has the `filter()` function. It is easier to use than selection using `dataframe[condition1 &amp; condition2]`

ðŸŽ¬ Keep rows of human proteins identified by more than one peptide:

```r
sol &lt;- sol %&gt;% 
  filter(str_detect(description, "OS=Homo sapiens")) %&gt;% 
  filter(x1pep == "x")
```

---
# Case study

ðŸ‘€ `str_detect(string, pattern)` returns a logical vector according to whether 'pattern' is found in 'string'.

ðŸ‘€ Notice that we have applied `filter()` twice using the pipe.

---
# Case study

**Processing cells contents**

It would be useful to extract the genename from the `description` and put it in a column of its own.

One entry from the `description` column looks like this:

.scroll-output-width[
.code60[

```r
sol$description[1]
```

```
## [1] "Neuroblast differentiation-associated protein AHNAK OS=Homo sapiens GN=AHNAK PE=1 SV=2"
```
]
]

--

The genename is after `GN=`. We need to extract the part of the string that follows `GN=` and put it in a new column. We need to do that for every row in of the dataframe.

---
# Case study

**Processing cells contents**

You can problem-solve your way to the result by breaking the steps down. Start with *one* value and perform operations one at a time until you've worked out the pipeline. Then implement on the entire column.

The pipe makes it especially easy to break problems down like this.

---
# Case study

**Processing cells contents**

One step at a time on one value.

We need to:
-  get one value from `description` to practice with
-  find `GN=` in the description
-  extract the string that starts `GN=`
-  remove the `GN=` part of that that string

ðŸŽ¬ Extract the first value of the `description` to work with:

```r
one_description &lt;- sol$description[1]
```

--

We could use `sol$description[2]` or `sol$description[100]` or any other row


---
# Case study

**Processing cells contents**

One step at a time on one value.

ðŸŽ¬ Extract the string that starts `GN=` using a regex:

```r
str_extract(one_description,"GN=[^\\s]+")
```

```
## [1] "GN=AHNAK"
```

Explanation on next slide.

---
# Case study

**Processing cells contents**

One step at a time on one value.


* `[ ]` means some characters
* `^` means 'not' when inside `[ ]`
* `\s` means white space  
* the `\` before is an escape character to indicate that the next character, `\` should not be taken literally (because it's part of `\s`)  
* `+` means one or more  

--

So `GN=[^\\s]+` means `GN=` followed by one or more characters that are not white space. This means the pattern stops matching at the first white space after "GN=".

---
# Case study

**Processing cells contents**

One step at a time on one value.

We're close. Now we will drop the `GN=` part by replacing it with nothing:

ðŸŽ¬ Add replacing `GN=` with an empty string, `""`, to the pipeline:

```r
str_extract(one_description, "GN=[^\\s]+") %&gt;% 
  str_replace("GN=", "")
```

```
## [1] "AHNAK"
```

--
.font140[
ðŸŽ‰
]
---
# Case study

**Processing cells contents**

Creating a new column

Now we know how to get the result for one value, we need to apply the same process to the whole column

--

`mutate()` is the **`dplyr`** function that adds new variables and preserves existing ones. It takes `name` = `value` pairs of expressions where:

* `name` is the name for the new variable and 
* `value` is the value it takes. This is usually an expression. 

---
# Case study

**Processing cells contents**

Creating a new column

ðŸŽ¬ Add a variable `genename` which contains the processed string from the `description` variable:

```r
sol &lt;- sol %&gt;%
  mutate(genename =  str_extract(description,"GN=[^\\s]+") %&gt;% 
           str_replace("GN=", ""))
```

---
# Case study

You will continue to work on this case study in the workshop.

---
# Summary

.font80[

-  **`tidyverse`** is a collection of packages with a common design; many excellent packages are not part of it  
-  `library(tidyverse)` loads the core packages; other **`tidyverse`** packages need their own `library()` call  
-  the pipe `%&gt;%` is key to connecting **`tidyverse`** tools together to create highly readable code  
-  reshaping data from wide to long format is common: `pivot_longer()`  
-  splitting cell contents is common: `extract()` 
-  regular expressions allow you to match text patterns; expect to have to google and do a lot of trial and error  
-  `clean_names()` is well useful!
-  `::` gives you access to a package's functions without using `library()`  
-  use particular rows `filter()`  
  

]

---
# Reading

## Strongly recommended

-  [article by Joe Rickert](https://rviews.rstudio.com/2017/06/08/what-is-the-tidyverse/) gives a good overview.
-  Tidy Data ([Wickham, 2014](#bib-Wickham2014-nl)) sections 1 and 2

## Further
-  Welcome to the Tidyverse ([Wickham Averick, et al., 2019](#bib-Wickham2019-ml)) 
-  Tidy Data ([Wickham, 2014](#bib-Wickham2014-nl)) sections 3 - 6
-  R for Data Science &lt;a name=cite-Wickham2017RDS3086927&gt;&lt;/a&gt;([Wickham and Grolemund, 2017](#bib-Wickham2017RDS3086927)) Chapter 12.1, to 12.3 and Chapter 18


---
# References
.font50[
.footnote[
Slides made with xaringan &lt;a name=cite-xaringan&gt;&lt;/a&gt;([Xie, 2021](#bib-xaringan)),  xaringanExtra &lt;a name=cite-xaringanExtra&gt;&lt;/a&gt;([Aden-Buie, 2020](#bib-xaringanExtra)), xaringanthemer &lt;a name=cite-xaringanthemer&gt;&lt;/a&gt;([Aden-Buie, 2021](#bib-xaringanthemer)) and RefManageR &lt;a name=cite-RefManageR&gt;&lt;/a&gt;([McLean, 2017](#bib-RefManageR)) 

]

&lt;a name=bib-xaringanExtra&gt;&lt;/a&gt;[Aden-Buie, G.](#cite-xaringanExtra)
(2020). _xaringanExtra: Extras And Extensions for Xaringan Slides_. R
package version 0.2.3.9000. URL:
[https://github.com/gadenbuie/xaringanExtra](https://github.com/gadenbuie/xaringanExtra).

&lt;a name=bib-xaringanthemer&gt;&lt;/a&gt;[Aden-Buie, G.](#cite-xaringanthemer)
(2021). _xaringanthemer: Custom 'xaringan' CSS Themes_. R package
version 0.4.0. URL:
[https://CRAN.R-project.org/package=xaringanthemer](https://CRAN.R-project.org/package=xaringanthemer).

&lt;a name=bib-R-biobroom&gt;&lt;/a&gt;[Bass, A. J., D. G. Robinson, et
al.](#cite-R-biobroom) (2020). _biobroom: Turn Bioconductor objects
into tidy data frames_. R package version 1.20.0. URL:
[https://github.com/StoreyLab/biobroom](https://github.com/StoreyLab/biobroom).

&lt;a name=bib-Codd1990-th&gt;&lt;/a&gt;[Codd, E. F.](#cite-Codd1990-th) (1990).
_The Relational Model for Database Management: Version 2_. Boston, MA,
USA: Addison-Wesley Longman Publishing Co., Inc. URL:
[https://dl.acm.org/doi/pdf/10.5555/77708](https://dl.acm.org/doi/pdf/10.5555/77708).

&lt;a name=bib-R-tidybulk&gt;&lt;/a&gt;[Mangiola, S.](#cite-R-tidybulk) (2020).
_tidybulk: Brings transcriptomics to the tidyverse_. R package version
1.0.2. URL:
[https://bioconductor.org/packages/release/bioc/html/tidybulk.html](https://bioconductor.org/packages/release/bioc/html/tidybulk.html).

&lt;a name=bib-RefManageR&gt;&lt;/a&gt;[McLean, M. W.](#cite-RefManageR) (2017).
"RefManageR: Import and Manage BibTeX and BibLaTeX References in R".
In: _The Journal of Open Source Software_. DOI:
[10.21105/joss.00338](https://doi.org/10.21105%2Fjoss.00338).

&lt;a name=bib-Wickham2014-nl&gt;&lt;/a&gt;[Wickham, H.](#cite-Wickham2014-nl)
(2014). "Tidy Data". In: _Journal of Statistical Software, Articles_
59.10, pp. 1-23. URL:
[https://vita.had.co.nz/papers/tidy-data.pdf](https://vita.had.co.nz/papers/tidy-data.pdf).

&lt;a name=bib-Wickham2019-ml&gt;&lt;/a&gt;[Wickham, H., M. Averick, et
al.](#cite-Wickham2019-ml) (2019). "Welcome to the Tidyverse". In:
_JOSS_ 4.43, p. 1686. URL:
[https://joss.theoj.org/papers/10.21105/joss.01686](https://joss.theoj.org/papers/10.21105/joss.01686).

&lt;a name=bib-usethis&gt;&lt;/a&gt;[Wickham, H. and J. Bryan](#cite-usethis)
(2021). _usethis: Automate Package and Project Setup_. R package
version 2.0.1. URL:
[https://CRAN.R-project.org/package=usethis](https://CRAN.R-project.org/package=usethis).

&lt;a name=bib-Wickham2017RDS3086927&gt;&lt;/a&gt;[Wickham, H. and G.
Grolemund](#cite-Wickham2017RDS3086927) (2017). _R for Data Science:
Import, Tidy, Transform, Visualize, and Model Data_. 1st. Accessed:
2021-11-22. O'Reilly Media, Inc. ISBN: 1491910399, 9781491910399. URL:
[https://r4ds.had.co.nz/](https://r4ds.had.co.nz/).

&lt;a name=bib-xaringan&gt;&lt;/a&gt;[Xie, Y.](#cite-xaringan) (2021). _xaringan:
Presentation Ninja_. R package version 0.22. URL:
[https://CRAN.R-project.org/package=xaringan](https://CRAN.R-project.org/package=xaringan).

]

.font70[
.footnote[
Slides made with with xaringan ([Xie, 2021](#bib-xaringan)) and xaringanExtra ([Aden-Buie, 2020](#bib-xaringanExtra))
]
]
---

## Emma Rand &lt;br&gt; [emma.rand@york.ac.uk](mailto:emma.rand@york.ac.uk) &lt;br&gt; Twitter: [@er13_r](https://twitter.com/er13_r) &lt;br&gt; GitHub: [3mmaRand](https://github.com/3mmaRand)  &lt;br&gt; blog: https://buzzrbeeline.blog/
&lt;br&gt;
&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;&lt;img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"&gt;Data Science strand of BIO00058M&lt;/span&gt; by &lt;span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName"&gt;Emma Rand&lt;/span&gt; is licensed under a &lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License&lt;/a&gt;.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
