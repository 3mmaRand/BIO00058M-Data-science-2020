---
title: "An introduction to Machine Learning: Overview"
subtitle: "Data Science option of BIO00058M Data Analysis."
author: "Emma Rand"
institute: "University of York, UK"
output:
  xaringan::moon_reader:
    css: [default, ../css_files/emma.css, ../css_files/emma-fonts.css]
    lib_dir: libs
    seal: true
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
    fig_caption: false
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE,	
                      warning = FALSE,
                      fig.width = 4, 
                      fig.height = 4, 
                      fig.retina = 3)
options(htmltools.dir.version = FALSE)
```

```{r style-share-again, echo=FALSE}
xaringanExtra::use_share_again()
xaringanExtra::style_share_again(
  share_buttons = "all")
xaringanExtra::use_clipboard()
xaringanExtra::use_extra_styles(
  hover_code_line = TRUE,         
  mute_unhighlighted_code = TRUE)
```

```{r packages, include=FALSE}
library(RefManageR)
library(kableExtra)
library(tidyverse)
```


```{r, load-refs, include=FALSE, cache=FALSE}
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           cite.style = "authoryear",
           style = "markdown",
           hyperlink = FALSE,
           dashed = FALSE,
           longnamesfirst = FALSE,
           max.names = 2)
myBib <- ReadBib("../refs.bib", check = FALSE)
```

<style>
div.blue { background-color:#b0cdef; border-radius: 5px; padding: 20px;}
div.grey { background-color:#d3d3d3; border-radius: 0px; padding: 0px;}
</style>

# Outline

The aim of these slides if to provide an short overview of machine learning and machine learning methods.

---
class: inverse

# What is Machine Learning?


---
# What is Machine Learning?

Machine learning is just statistics!

It is used to explore, summarise, visualise and model data.

--

It can be used for:

* visualisation of high dimensional data  
* discovering patterns/clusters in variables or observations  
* making predictions  
* classifying observations

---
# What is Machine Learning?

In Stage 1 the type of data analysis we did was hypothesis testing. We typically have relatively few explanatory variables and usually a single response.

--

From this perspective, the goals are to explain a response, and determine whether specific variables have a significant effect on the response. 

--

Being able to interpret the model is important so we favour the simplest model that explains a significant amount of variation in the response.

--

Typically the entire dataset is modelled.

---
# What is Machine Learning?

In machine learning the analysis is often exploratory. It might generate hypotheses rather than test one. It is also used to pre-processed data for hypothesis testing.

--

In predictive machine learning the goal is often the quality of the predictions - how the predictions arise is less important. 

--

Models often have many variables and we are less concerned with the significance of a single variable.

--

In predictive machine learning typically 75% of the data are used to train (build) the model with 25% reserved for testing.

---
class: inverse

# Categories of ML methods


---
# Categories of ML methods

ML methods can be characterised as **supervised** or **unsupervised**.

--

Supervised methods are used for prediction and classification. 

--

With supervised learning both the inputs and the outputs are given to the algorithm. The goal is to find the rules to map the inputs to outputs.

--

We train the model (find the rules) on 75% of the data and test it on the remaining 25%.

---
# Categories of ML methods

Unsupervised methods are usually used for exploration, visualisation and data reduction.

Data reduction is often needed for high dimensional data. It means creating fewer new variables from the many original ones to make the data easier to analyse and visualise.

--

Unsupervised methods are unsupervised in that they do not use/optimise to a particular output. The goal is to uncover structure.

---
class: inverse

# Supervised methods

---
# Supervised methods

Examples are

Parametric - relatively fast, make assumptions  
* Linear regression - prediction of continuous output  
* Logistic regression - prediction of binary output (classification)  
* Linear Discriminant Analysis - prediction of more than two classes  

Non-parametric - can be slow, can be stochastic   
* Decision trees  
* Naive Bayes
* Support vector machines  
* K nearest neighbour

---
class: inverse

# Unsupervised methods

---
# Unsupervised methods

Examples are

Parametric - relatively fast, make assumptions  
* Principal Component Analysis    
* Metric Multidimensional scaling  
* many clustering methods  

Non-parametric - can be slow, can be stochastic   
* K means clustering (no relation to K nearest neighbour).  
* Non-Metric Multidimensional scaling
* *t*-distributed stochastic neighbour embedding

---
# References
.font50[
.footnote[
Slides made with xaringan `r Cite(myBib, "xaringan")`,  xaringanExtra `r Cite(myBib, "xaringanExtra")`, xaringanthemer `r Cite(myBib, "xaringanthemer")` and RefManageR `r Cite(myBib, "RefManageR")` 

]

```{r refs, echo=FALSE, results="asis"}
PrintBibliography(myBib)
```

]
---

Emma Rand <br> [emma.rand@york.ac.uk](mailto:emma.rand@york.ac.uk) <br> Twitter: [@er13_r](https://twitter.com/er13_r) <br> GitHub: [3mmaRand](https://github.com/3mmaRand)  <br> blog: https://buzzrbeeline.blog/
<br>
<br>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br /><span xmlns:dct="http://purl.org/dc/terms/" property="dct:title">Data Science strand of BIO00058M</span> by <span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName">Emma Rand</span> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.l