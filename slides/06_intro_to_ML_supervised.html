<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>An introduction to Machine Learning: Supervised methods</title>
    <meta charset="utf-8" />
    <meta name="author" content="Emma Rand" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/shareon/shareon.min.css" rel="stylesheet" />
    <script src="libs/shareon/shareon.min.js"></script>
    <link href="libs/xaringanExtra-shareagain/shareagain.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-shareagain/shareagain.js"></script>
    <link href="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link href="libs/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <link rel="stylesheet" href="../css_files/emma.css" type="text/css" />
    <link rel="stylesheet" href="../css_files/emma-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# An introduction to Machine Learning: Supervised methods
## Data Science option of BIO00058M Data Analysis.
### Emma Rand
### University of York, UK

---



<style>.shareagain-bar {
--shareagain-foreground: rgb(255, 255, 255);
--shareagain-background: rgba(0, 0, 0, 0.5);
}</style>






&lt;style&gt;
div.blue { background-color:#b0cdef; border-radius: 5px; padding: 20px;}
div.grey { background-color:#d3d3d3; border-radius: 0px; padding: 0px;}
&lt;/style&gt;


# Outline

In a previous topic you were introduced to Machine Learning. You learnt that ML is statistics and can be used for:

* visualisation of high dimensional data  
* discovering patterns/clusters in variables or observations  
* making predictions  
* classifying observations  

--

You also learnt that ML methods can be characterised as **supervised** or **unsupervised**.

You learnt to apply two unsupervised methods: Principal Component Analysis (PCA) and *t*-distributed Stochastic neighbour embedding (*t*-SNE)

---
# Outline

The aim of this topic is to introduce you to a supervised learning method called Linear Discriminant Analysis.

It will demonstrate concepts that also apply to other supervised methods: overfitting, training and testing and confusion matrices. 

---
class: inverse

# Linear Discriminant Analysis

---
# Linear Discriminant Analysis

Linear Discriminant Analysis (LDA) aims to find linear combination of variables the maximise differences between groups. 

--

It is supervised because we *label* observations by their group.

--

A 'linear discriminant' (LD) is a linear combination of variables that best separates the groups. If there are `\(n\)` groups we have, at most, `\(n-1\)` discriminants. 

--

The `lda()` function is in a package called **`MASS`** (Venables and Ripley, 2002) which is part of the base R distribution so you do not need to install it. 

ðŸ“¢ Do not load the package!


---
# Training and testing

During hypothesis testing the goal is to explain a response and determine whether specific variables have a significant effect on the response. Typically, we use all our data. 

--

One problem with this approach is not knowing how generalisable our model is. That is, we do not know how well the model would predict the responses for a new data set.  

--

When a model fits the data you have very well but does not generalise, it is known as *overfitting*.
You can think of it as fitting the random variation in the data in addition to the non-random variation.

---
# Training and testing

To avoid overfitting in supervised ML methods we build - or train - the model on approximately 75% of the data and then test it on the remaining 25%. 

--

The **`caret`** package (Kuhn, 2020) includes functions to facilitate training and testing  - in addition to many ML algorithms. 

--

The name comes from **C**lassification&lt;sup&gt;1&lt;/sup&gt; **A**nd **RE**gression **T**raining. Max Kuhn's work on ML in R has been extremely influential. 

--

His most recent work is on tidymodels (Kuhn and Wickham, 2020) a collection of packages for modelling and ML using the tidyverse paradigm.

.footnote[
.font60[
1. We often use the word "class" rather than "group" in ML
]
]
---
# Outline

In these slideshow you will apply:

* LDA to the Penguin data *without* training and testing  
* LDA to the Penguin data *with* training and testing  
* LDA to the scRNASeq data *with* training and testing but we will consider how good the model is at predicting classes from the training set compared to the test set. 

--

These will help you understand *why* we do training and testing but note that we would *not* normally first do ML without training and testing and then do it with training and testing.

---
# Outline

You should be able to code along with the examples. When you see the film clapper it is..

ðŸŽ¬ .. an instruction to do something!!

--

There is also demo on the scRNASeq data

---
# Set up

I suggest having a different RStudio Project for each dataset. Consider using those you created for the unsupervised ML.

--

Note that you can have multiple instances of RStudio running to allow you to work on more than one RStudio Project.


---
# Set up

Load the **`tidyverse`**, **`caret`** and **`GGally`** and for each RStudio Project.


```r
library(tidyverse)
library(caret)
library(GGally)
```

Do not load **`MASS`**. We will access the `lda()` function with `MASS::lda()` instead.


---
class: inverse

#  LDA on Penguins without training and testing


---
# Penguin LDA

You can read more about the Palmer penguins dataset in [Introduction to palmerpenguins](https://allisonhorst.github.io/palmerpenguins/articles/intro.html).


ðŸŽ¬ Load the package to get the data: 

```r
library(palmerpenguins)
```

ðŸŽ¬ Clean the variable names for ease of use: 

```r
penguin &lt;- penguins_raw %&gt;%
  janitor::clean_names()
```

---
# Penguin LDA: tidy

We repeat the simple filtering and tidying we did previously.

ðŸŽ¬ Filter out the rows with missing values: 


```r
penguin &lt;- penguin %&gt;% 
  filter(!is.na(body_mass_g)) %&gt;% 
  filter(!is.na(sex))
```

ðŸŽ¬ Split `species` into `common_name` and `scientific_name`: 

```r
penguin &lt;- penguin %&gt;% 
  extract(species, 
          c("common_name", "scientific_name"),
          "([a-zA-Z]+\\s[a-zA-Z]+)\\s\\(([a-zA-Z]+\\s[a-zA-Z]+)\\)")
```


---
# Penguin LDA: build model

Now to run the LDA. 

ðŸŽ¬ Select the four variables and pipe into the `MASS::lda()` function which does the LDA:


```r
lda &lt;- penguin %&gt;% 
  select(body_mass_g,
         ends_with("_mm")) %&gt;%
  MASS::lda(grouping = penguin$common_name)
```

--

We have saved the result to a list object called `lda`

---
# Penguin LDA: build model

We definitely want to use `package::function()`. 

**`MASS`** has a function called `select()` and so does **`dplyr`**, but they work differently.

If you load **`MASS`** after **`dplyr`** (or after **`tidyverse`**) `MASS::select()` will be used rather than `dplyr::select()` 

You can spend hours of your life wondering what is wrong with your code when it looks fine and worked before you loaded both packages. I have done this with these particular functions too many times!

---
# Penguin LDA: examine model

Just as we could see the importance of each variable in each Principal Component using `pca$loadings`, we can see the importance of each variable in each discriminant using `lda$scaling`.

ðŸŽ¬ View the importance of each variable in each discriminant:
.code70[

```r
lda$scaling
```

```
##                         LD1       LD2
## body_mass_g        0.001347 -0.001686
## culmen_length_mm   0.085927  0.416602
## culmen_depth_mm   -1.041647  0.010423
## flipper_length_mm  0.084553 -0.014246
```
]


---
# Penguin LDA: examine model

`\(LD1=\)` 0.0013 `\(body\_mass\_g +\)`  0.0859 `\(culmen\_length\_mm +\)` -1.0416 `\(culmen\_depth\_mm +\)` 0.0846 `\(flipper\_length\_mm\)`

You might want to compare to the [loadings for PCA](05_intro_to_ML_unsupervised.html#43)

---
# Penguin LDA: predict classes

To find what species is predicted by the model for each observation (row) we can use `predict()`. 
ðŸŽ¬ Select the model variables from `Penguin` and predict the species from the `lda` model object:


```r
plda &lt;- penguin %&gt;% 
  select(body_mass_g,
         ends_with("_mm")) %&gt;%
  predict(object = lda)
```

---
# Penguin LDA: Confusion matrix

A **confusion matrix** is a table that tells us about the performance of a classification model.

--

The table gives the number of:

* correct predictions: the species predicted matches the observed species  
* incorrect predictions: the species predicted does not match the observed species.
for each species.  

--

**`caret`** provides us with a useful function to examine the confusion matrix. 

---
# Penguin LDA: Confusion matrix

The `confusionMatrix()` function also outputs:

-  Accuracy - Number of correct predictions / Number of observations 
-  95% CI - 95 percent confidence interval on the accuracy (using `binom.test()`)  
-  No Information Rate - Number of observations in the largest class / Total number of observations. If you had no other information, the best prediction would be the commonest class. In other words, the NIR is the best you could do by chance.   
-  P-Value [Acc &gt; NIR] - Is the model significantly better than than you could do by always predicting the most common class (again using `binom.test()`).  

---
# Penguin LDA: Confusion matrix

ðŸŽ¬ Examining the confusion matrix:


.scroll-output-height[

```r
confusionMatrix(plda$class, factor(penguin$common_name))
```

```
## Confusion Matrix and Statistics
## 
##                    Reference
## Prediction          Adelie Penguin Chinstrap penguin Gentoo penguin
##   Adelie Penguin               145                 3              0
##   Chinstrap penguin              1                65              0
##   Gentoo penguin                 0                 0            119
## 
## Overall Statistics
##                                              
##                Accuracy : 0.988              
##                  95% CI : (0.97, 0.997)      
##     No Information Rate : 0.438              
##     P-Value [Acc &gt; NIR] : &lt;0.0000000000000002
##                                              
##                   Kappa : 0.981              
##                                              
##  Mcnemar's Test P-Value : NA                 
## 
## Statistics by Class:
## 
##                      Class: Adelie Penguin Class: Chinstrap penguin
## Sensitivity                          0.993                    0.956
## Specificity                          0.984                    0.996
## Pos Pred Value                       0.980                    0.985
## Neg Pred Value                       0.995                    0.989
## Prevalence                           0.438                    0.204
## Detection Rate                       0.435                    0.195
## Detection Prevalence                 0.444                    0.198
## Balanced Accuracy                    0.989                    0.976
##                      Class: Gentoo penguin
## Sensitivity                          1.000
## Specificity                          1.000
## Pos Pred Value                       1.000
## Neg Pred Value                       1.000
## Prevalence                           0.357
## Detection Rate                       0.357
## Detection Prevalence                 0.357
## Balanced Accuracy                    1.000
```
]

---
# Penguin LDA: Confusion matrix




-  The model had an accuracy of 98.8%.  
-  there were 146 Adelie Penguins of which 1 were predicted incorrectly.  
-  68 Chinstrap Penguins of which 3 were predicted incorrectly.  
-  and 119 Gentoo Penguins of which 0 were predicted incorrectly.

---
# Penguin LDA: plot

We can plot the scores on each of the new axes and colour them by species. The scores are in a variable called `$x` in `plda`

ðŸŽ¬ Extract the scores into a dataframe with the species names: 

```r
lda_labelled &lt;- data.frame(plda$x,
                              common_name = penguin$common_name)
```

ðŸŽ¬ Create a scatter plot: 


```r
lda_labelled %&gt;% 
  ggplot(aes(x = LD1, y = LD2, color = common_name)) +
  geom_point() 
```

---
# Penguin LDA: plot

&lt;img src="06_intro_to_ML_supervised_files/figure-html/unnamed-chunk-13-1.png" width="1200" /&gt;

The separation between species is stronger in the LDA than in the[ PCA.](05_intro_to_ML_unsupervised.html#44)

---
class: inverse


#  LDA on Penguins with training and testing

---
# Penguin LDA: Train &amp; test

We used the same data to train the LDA model as we used to examine its performance. Few were incorrectly classified. But this is not very robust - we could have overfitting.

We can use the **`caret`** function `createDataPartition()` to split the dataset in to training and testing sets. 

--

It returns a proportion of row numbers randomly sampled from the dataframe.

---
# Penguin LDA: Create train &amp; test sets

ðŸŽ¬ Create a vector of row numbers that will be used to split the dataset in to training and testing sets:

```r
ids &lt;- createDataPartition(y = penguin$common_name,
                           p = 0.75,
                           list = FALSE)
```

`p` is the proportion of rows to sample.

`list = FALSE` gives me a vector of numbers rather than a one-item list.

You might want to examine the `ids` variable.

---
# Penguin LDA: Create training set

Now we use those row numbers to select the rows from `penguin` to create the training and test datasets. We use the `dplyr` function slice which works like the filter function but filters rows on their index rather than a match to a condition.

ðŸŽ¬ Create the training set:

```r
train &lt;- penguin %&gt;% slice(ids)
```

---
# Penguin LDA: Create testing set

The testing set is all the rows that are not in `ids`.

ðŸŽ¬ Create the testing set:

```r
test &lt;- penguin %&gt;% slice(-ids)
```

--

You might want to examine the two dataframes, `train` and `test`, we just made.

---
# Penguin LDA: train model

The process of using `lda()` and `predict()` is the same as previously but we use different input data.

ðŸŽ¬ Perform the LDA on the **training data**:

```r
*lda &lt;- train %&gt;%
  select(body_mass_g,
         ends_with("_mm")) %&gt;%
* MASS::lda(grouping = train$common_name)
```

---
# Penguin LDA: test model

ðŸŽ¬ And predict classes of the **test data**:



```r
*plda &lt;- test %&gt;%
  select(body_mass_g,
         ends_with("_mm")) %&gt;%
  predict(object = lda)
```

---
# Penguin LDA: Confusion matrix

ðŸŽ¬ Examining the confusion matrix:
.scroll-output-height[

```r
confusionMatrix(plda$class,factor(test$common_name))
```

```
## Confusion Matrix and Statistics
## 
##                    Reference
## Prediction          Adelie Penguin Chinstrap penguin Gentoo penguin
##   Adelie Penguin                36                 2              0
##   Chinstrap penguin              0                15              0
##   Gentoo penguin                 0                 0             29
## 
## Overall Statistics
##                                              
##                Accuracy : 0.976              
##                  95% CI : (0.915, 0.997)     
##     No Information Rate : 0.439              
##     P-Value [Acc &gt; NIR] : &lt;0.0000000000000002
##                                              
##                   Kappa : 0.962              
##                                              
##  Mcnemar's Test P-Value : NA                 
## 
## Statistics by Class:
## 
##                      Class: Adelie Penguin Class: Chinstrap penguin
## Sensitivity                          1.000                    0.882
## Specificity                          0.957                    1.000
## Pos Pred Value                       0.947                    1.000
## Neg Pred Value                       1.000                    0.970
## Prevalence                           0.439                    0.207
## Detection Rate                       0.439                    0.183
## Detection Prevalence                 0.463                    0.183
## Balanced Accuracy                    0.978                    0.941
##                      Class: Gentoo penguin
## Sensitivity                          1.000
## Specificity                          1.000
## Pos Pred Value                       1.000
## Neg Pred Value                       1.000
## Prevalence                           0.354
## Detection Rate                       0.354
## Detection Prevalence                 0.354
## Balanced Accuracy                    1.000
```
]


The model had an accuracy of 97.56%. You may have greater or fewer because the training and testing sets were random selections.

---
class: inverse

#  LDA on single-cell RNASeq data with training and testing


---
# scRNASeq LDA

The data in [scrna_data.csv](../data-raw/scrna_data.csv) and [scrna_meta.csv](../data-raw/scrna_meta.csv) are the single-cell  RNASeq data we considered last week. Each row is a cell (an observation) and each column is a gene (a variable / feature). The values are gene expression values.

ðŸŽ¬ Import the data and the cell labels: 

```r
file &lt;- "../data-raw/scrna_data.csv"
rna &lt;- read_csv(file)
file &lt;- "../data-raw/scrna_meta.csv"
meta &lt;- read_csv(file) %&gt;% select(louvain)
```

---
# scRNASeq LDA

ðŸŽ¬ Add the cell labels to the data: 


```r
rna$cell &lt;- meta$louvain
```

---
# scRNASeq LDA: create train &amp; test sets


ðŸŽ¬ Split the dataset in to training and testing sets using `createDataPartition()`

```r
ids &lt;- createDataPartition(y = rna$cell,
                           p = 0.75,
                           list = FALSE)
```


---
# scRNASeq LDA: create train &amp; test sets

Now we use those row numbers to select the rows from `rna` to create the training and test datasets. 

ðŸŽ¬ Create the training set:

```r
train &lt;- rna %&gt;% slice(ids)
```

ðŸŽ¬ Create the testing set:

```r
test &lt;- rna %&gt;% slice(-ids)
```

---
# scRNASeq LDA: train model

ðŸŽ¬ Perform the LDA on the training data:

```r
lda &lt;- train %&gt;% 
  select(-cell) %&gt;%
  MASS::lda(grouping = train$cell)
```

---
# scRNASeq LDA: Performance
Now we will compare how well our model performs on the training data campare to the test data.

How well does our model perform on the training data?

ðŸŽ¬ Predict on the training data:



```r
plda_train &lt;- train %&gt;% 
  select(-cell) %&gt;%
  predict(object = lda)
```

---
# scRNASeq LDA: Confusion matrix

ðŸŽ¬ Examining the confusion matrix:
.scroll-output-height[

```r
confusionMatrix(plda_train$class,factor(train$cell))
```

```
## Confusion Matrix and Statistics
## 
##                    Reference
## Prediction          B CELLS CD14+ Monocytes CD4 T CD8 T Dendritic
##   B CELLS               256               0     0     0         0
##   CD14+ Monocytes         0             360     0     0         0
##   CD4 T                   0               0   865     0         0
##   CD8 T                   0               0     0   228         0
##   Dendritic               0               0     0     0        27
##   FCGR3A+ Monocytes       0               0     0     0         0
##   Megakaryocytes          0               0     0     0         0
##   NK CELLS                0               0     0     0         0
##                    Reference
## Prediction          FCGR3A+ Monocytes Megakaryocytes NK CELLS
##   B CELLS                           0              0        0
##   CD14+ Monocytes                   0              0        0
##   CD4 T                             0              0        0
##   CD8 T                             0              0        0
##   Dendritic                         0              0        0
##   FCGR3A+ Monocytes               115              0        0
##   Megakaryocytes                    0             12        0
##   NK CELLS                          0              0      118
## 
## Overall Statistics
##                                              
##                Accuracy : 1                  
##                  95% CI : (0.998, 1)         
##     No Information Rate : 0.437              
##     P-Value [Acc &gt; NIR] : &lt;0.0000000000000002
##                                              
##                   Kappa : 1                  
##                                              
##  Mcnemar's Test P-Value : NA                 
## 
## Statistics by Class:
## 
##                      Class: B CELLS Class: CD14+ Monocytes Class: CD4 T
## Sensitivity                   1.000                  1.000        1.000
## Specificity                   1.000                  1.000        1.000
## Pos Pred Value                1.000                  1.000        1.000
## Neg Pred Value                1.000                  1.000        1.000
## Prevalence                    0.129                  0.182        0.437
## Detection Rate                0.129                  0.182        0.437
## Detection Prevalence          0.129                  0.182        0.437
## Balanced Accuracy             1.000                  1.000        1.000
##                      Class: CD8 T Class: Dendritic Class: FCGR3A+ Monocytes
## Sensitivity                 1.000           1.0000                   1.0000
## Specificity                 1.000           1.0000                   1.0000
## Pos Pred Value              1.000           1.0000                   1.0000
## Neg Pred Value              1.000           1.0000                   1.0000
## Prevalence                  0.115           0.0136                   0.0581
## Detection Rate              0.115           0.0136                   0.0581
## Detection Prevalence        0.115           0.0136                   0.0581
## Balanced Accuracy           1.000           1.0000                   1.0000
##                      Class: Megakaryocytes Class: NK CELLS
## Sensitivity                        1.00000          1.0000
## Specificity                        1.00000          1.0000
## Pos Pred Value                     1.00000          1.0000
## Neg Pred Value                     1.00000          1.0000
## Prevalence                         0.00606          0.0596
## Detection Rate                     0.00606          0.0596
## Detection Prevalence               0.00606          0.0596
## Balanced Accuracy                  1.00000          1.0000
```
]


The model had an accuracy of 100%. Wow, that's good. Or is it??

---
# scRNASeq LDA: Performance on test

But what about performance on the test set? Is our modelling overftting? Would it be equally good on the scRNASeq data for a new dataset?

ðŸŽ¬ Predict classes of the test data based on LDA model:


```r
plda_test &lt;- test %&gt;% 
  select(-cell) %&gt;%
  predict(object = lda)
```

---
# scRNASeq LDA: Confusion matrix

ðŸŽ¬ Examining the confusion matrix:
.scroll-output-height[

```r
confusionMatrix(plda_test$class, factor(test$cell))
```

```
## Confusion Matrix and Statistics
## 
##                    Reference
## Prediction          B CELLS CD14+ Monocytes CD4 T CD8 T Dendritic
##   B CELLS                68               1    17     1         1
##   CD14+ Monocytes         5              90    24     6         2
##   CD4 T                   7               8   164    11         0
##   CD8 T                   2               5    55    48         0
##   Dendritic               2               1     1     0         4
##   FCGR3A+ Monocytes       1              10    20     2         1
##   Megakaryocytes          0               0     0     0         0
##   NK CELLS                0               5     7     7         1
##                    Reference
## Prediction          FCGR3A+ Monocytes Megakaryocytes NK CELLS
##   B CELLS                           0              0        0
##   CD14+ Monocytes                   2              0        1
##   CD4 T                             5              0        4
##   CD8 T                             1              0        3
##   Dendritic                         1              1        0
##   FCGR3A+ Monocytes                29              1        0
##   Megakaryocytes                    0              1        0
##   NK CELLS                          0              0       31
## 
## Overall Statistics
##                                              
##                Accuracy : 0.662              
##                  95% CI : (0.625, 0.698)     
##     No Information Rate : 0.438              
##     P-Value [Acc &gt; NIR] : &lt;0.0000000000000002
##                                              
##                   Kappa : 0.569              
##                                              
##  Mcnemar's Test P-Value : NA                 
## 
## Statistics by Class:
## 
##                      Class: B CELLS Class: CD14+ Monocytes Class: CD4 T
## Sensitivity                   0.800                  0.750        0.569
## Specificity                   0.965                  0.926        0.905
## Pos Pred Value                0.773                  0.692        0.824
## Neg Pred Value                0.970                  0.943        0.729
## Prevalence                    0.129                  0.183        0.438
## Detection Rate                0.104                  0.137        0.250
## Detection Prevalence          0.134                  0.198        0.303
## Balanced Accuracy             0.883                  0.838        0.737
##                      Class: CD8 T Class: Dendritic Class: FCGR3A+ Monocytes
## Sensitivity                0.6400          0.44444                   0.7632
## Specificity                0.8866          0.99074                   0.9435
## Pos Pred Value             0.4211          0.40000                   0.4531
## Neg Pred Value             0.9503          0.99227                   0.9848
## Prevalence                 0.1142          0.01370                   0.0578
## Detection Rate             0.0731          0.00609                   0.0441
## Detection Prevalence       0.1735          0.01522                   0.0974
## Balanced Accuracy          0.7633          0.71759                   0.8533
##                      Class: Megakaryocytes Class: NK CELLS
## Sensitivity                        0.33333          0.7949
## Specificity                        1.00000          0.9676
## Pos Pred Value                     1.00000          0.6078
## Neg Pred Value                     0.99695          0.9868
## Prevalence                         0.00457          0.0594
## Detection Rate                     0.00152          0.0472
## Detection Prevalence               0.00152          0.0776
## Balanced Accuracy                  0.66667          0.8813
```
]


The model had an accuracy of 66.21%. That is much more honest and robust test.
---
# scRNASeq LDA: plots

We will plot the training data and then the test data.

ðŸŽ¬ Extract the scores from the training set with the cell names: 

```r
lda_labelled_train &lt;- data.frame(plda_train$x,
                              cell = train$cell)
```

ðŸŽ¬ Extract the scores from the training set with the cell names: 

```r
lda_labelled_test &lt;- data.frame(plda_test$x,
                              cell = test$cell)
```
---
# scRNASeq LDA: LD1 and LD2

ðŸŽ¬ Create a scatter plot for the training data: 


```r
lda_labelled_train %&gt;% 
  ggplot(aes(x = LD1, y = LD2, color = cell)) +
  geom_point() 
```

---
# scRNASeq LDA

&lt;img src="06_intro_to_ML_supervised_files/figure-html/unnamed-chunk-35-1.png" width="700px" height="550px" /&gt;

---
# scRNASeq LDA: plots

Based on this plot, you might be surprised by the accuracy of the model predictions on the training set - there seems to be a lot of overlap.

--

However, you are only looking at LD1 and LD2. There are many dimensions in this dataset and the separation of groups might not be obvious from the first to LD.

--

**`GGally`** (Schloerke Cook, et al., 2020) can let us examine several pairwise LD comparisons.

---
# scRNASeq LDA: More LD

ðŸŽ¬ Select the first 5 LDs and pipe in to `ggpairs()`: 


```r
lda_labelled_train %&gt;% 
  select(LD1:LD5, cell) %&gt;% 
  ggpairs(aes(color = cell))
```


---
# scRNASeq LDA: More LD

&lt;img src="06_intro_to_ML_supervised_files/figure-html/unnamed-chunk-36-1.png" width="580px" height="580px" /&gt;

---
# scRNASeq LDA:

You can see how LD1 really separates Megakaryocytes from the other cell types but that other LD are needed to distinguish all the cell types.

--

Now consider the test set.

---
# scRNASeq LDA: LD1 and LD2

ðŸŽ¬ Create a scatter plot for the test data: 


```r
lda_labelled_test %&gt;% 
  ggplot(aes(x = LD1, y = LD2, color = cell)) +
  geom_point() 
```

---
# scRNASeq LDA

&lt;img src="06_intro_to_ML_supervised_files/figure-html/unnamed-chunk-37-1.png" width="700px" height="550px" /&gt;

---
# scRNASeq LDA: plots

There's a lot of overlap here. Perhaps we will better see the difference by examining additional LDs. However, remember that the predictions were less good on the test set so we would expect it to be difficult to distinguish all cells.



---
# scRNASeq LDA: More LD

ðŸŽ¬ Select the first 5 LDs and pipe in to `ggpairs()`: 


```r
lda_labelled_test %&gt;% 
  select(LD1:LD5, cell) %&gt;% 
  ggpairs(aes(color = cell))
```


---
# scRNASeq LDA

&lt;img src="06_intro_to_ML_supervised_files/figure-html/unnamed-chunk-38-1.png" width="580px" height="580px" /&gt;


---
# Summary

.font80[

* Linear discriminant analysis is a supervised ML method  
* It is applied when you have many continuous variables and allows you to visualised the data in fewer dimensions, and thus see group/patterns more easily.  
* LDA is a fast, linear, parametric method  
* the maximum number of discrimants is one fewer than the number of dimensions.
* overfitting occurs when a model too closely fits a limited set of data points and does not generalise  
* partitioning data into training and testing sets is the primary way to avoid overfitting  
* the performance of a classification model can be evaluated using a confusion matrix  
]

---
# Reading

## Strongly recommended

* The Assessment information!


---
# References
.font50[
.footnote[
Slides made with xaringan (Xie, 2021),  xaringanExtra (Aden-Buie, 2020), xaringanthemer (Aden-Buie, 2021) and RefManageR (McLean, 2017) 

]

Aden-Buie, G. (2020). _xaringanExtra: Extras And Extensions for
Xaringan Slides_. R package version 0.2.3.9000. URL:
[https://github.com/gadenbuie/xaringanExtra](https://github.com/gadenbuie/xaringanExtra).

Aden-Buie, G. (2021). _xaringanthemer: Custom 'xaringan' CSS Themes_. R
package version 0.4.0. URL:
[https://CRAN.R-project.org/package=xaringanthemer](https://CRAN.R-project.org/package=xaringanthemer).

Kuhn, M. (2020). _caret: Classification and Regression Training_. R
package version 6.0-86. URL:
[https://CRAN.R-project.org/package=caret](https://CRAN.R-project.org/package=caret).

Kuhn, M. and H. Wickham (2020). _Tidymodels: a collection of packages
for modeling and machine learning using tidyverse principles._ URL:
[https://www.tidymodels.org](https://www.tidymodels.org).

McLean, M. W. (2017). "RefManageR: Import and Manage BibTeX and
BibLaTeX References in R". In: _The Journal of Open Source Software_.
DOI: [10.21105/joss.00338](https://doi.org/10.21105%2Fjoss.00338).

Schloerke, B., D. Cook, et al. (2020). _GGally: Extension to
'ggplot2'_. R package version 2.0.0. URL:
[https://CRAN.R-project.org/package=GGally](https://CRAN.R-project.org/package=GGally).

Venables, W. N. and B. D. Ripley (2002). _Modern Applied Statistics
with S_. Fourth. ISBN 0-387-95457-0. New York: Springer. URL:
[http://www.stats.ox.ac.uk/pub/MASS4/](http://www.stats.ox.ac.uk/pub/MASS4/).

Xie, Y. (2021). _xaringan: Presentation Ninja_. R package version 0.22.
URL:
[https://CRAN.R-project.org/package=xaringan](https://CRAN.R-project.org/package=xaringan).

]
---

Emma Rand &lt;br&gt; [emma.rand@york.ac.uk](mailto:emma.rand@york.ac.uk) &lt;br&gt; Twitter: [@er13_r](https://twitter.com/er13_r) &lt;br&gt; GitHub: [3mmaRand](https://github.com/3mmaRand)  &lt;br&gt; blog: https://buzzrbeeline.blog/
&lt;br&gt;
&lt;br&gt;
&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;&lt;img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"&gt;Data Science strand of BIO00058M&lt;/span&gt; by &lt;span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName"&gt;Emma Rand&lt;/span&gt; is licensed under a &lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License&lt;/a&gt;.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
