---
title: "Topic 2: Tidying data and the tidyverse"
author: "Emma Rand"
output:
  html_document:
    toc: true
    depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: false
    theme: flatly
  word_document: default
bibliography: "../refs.bib"
---


![](../pics/58M.png)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.5442490.svg)](https://doi.org/10.5281/zenodo.5442490)

<!-- note for 2022 update, switch chaffinch example to subspecies -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE)
```

```{r include=FALSE}
library(RefManageR)
library(tidyverse)
```


```{r, load-refs, include=FALSE, cache=FALSE}
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           cite.style = "authoryear",
           style = "markdown",
           hyperlink = FALSE,
           dashed = FALSE,
           longnamesfirst = FALSE,
           max.names = 2)
myBib <- ReadBib("../refs.bib", check = FALSE)
```

# Week Overview

## Aim
The aim of this session is to strengthen your understanding of the concept of tidy data `r Cite(myBib, "Wickham2014-nl")`, introduce you to the tidyverse `r Cite(myBib, "Wickham2019-ml")` including the pipe,  and some commonly applied data tidying operations

## Objectives
By the end of this week the successful student should be able to:

-  explain what is meant by, and recognise tidy data
-  understand what the tidyverse is and appreciate tidyverse conventions
-  use pipes to link operations together
-  reshape data between 'long' and 'wide' formats
-  rename and recode variables
-  split and or extract cell contents over several columns
-  recognise and regex and write some regex of their own


# Set up

For each Task, go through the workflow for creating a [new RStudio Project](https://3mmarand.github.io/BIO00058M-Data-science-2020/workshops/01_project_organisation.html#Task_1_New_RStudio_Project) with the **`usethis`** `r Cite(myBib, "usethis")`. Use sensible RStudio Project names and folder structures.   



# Task 1

The data given in [Human-development-index.csv](../data-raw/Human-development-index.csv) give the [Human Development Index](http://hdr.undp.org/en/content/human-development-index-hdi) (HDI) for different countries since 1990.

`r emo::ji("clapper")` Using tidyverse functions, import these data and reformat them in to a more 'tidy' form.
```{r task-1-import}
# assumes you have loaded the tidyverse
file <- "../data-raw/Human-development-index.csv"
hdi <- read_csv(file) %>% 
  janitor::clean_names()

# I have used janitor::clean_names() to ensure the column names are lowercase without spaces and that the year columns have an x in front of them. both these mean I will not need to use backticks around column names such as hdi$`HDI Rank (2018)` and hdi$`1990`  
```

```{r task-1-tidy}
# the format of the data would be improved by having a single observation (i.e., index) per row with other columns giving the country, year and 2018 rank.
# this can be done using pivot_longer()  
hdi <- hdi %>%
  pivot_longer(names_to = "year", 
         values_to = "index",
         cols = -c(hdi_rank_2018, country)) 
# remove the x from the year and make it numeric
hdi <- hdi %>%
  mutate(year =  str_replace(year, "x", "") %>% as.numeric())
```
You should end up with a dataframe that has `r dim(hdi)[1]` rows. I used the name `hdi` for this.

`r emo::ji("clapper")` Not all countries have an index for all years. Filter the dataset to exclude the missing observations. You'll probably need to google here. Hint: the `is.na()` function may be useful.
```{r task-1-filter}
hdi_no_na <-  hdi %>%  
  filter(!is.na(index))
```
You should end up with a dataframe that has `r dim(hdi_no_na)[1]` rows. I used the name `hdi_no_na` for this.

The tidyverse way of summarising data is to combine the `group_by()` function with the `summarise()` function. For example, to get the mean index by country we would use:
```{r echo=TRUE, task-1-summarise-1}
hdi_summary <- hdi_no_na %>% 
  group_by(country) %>% 
  summarise(mean_index = mean(index))
```

We can add summary columns by adding the code needed to create them in to the `summarise()` function. So for example, to add the number of indices available for a country to a column we use:
```{r echo=TRUE, task-1-summarise-2}
hdi_summary <- hdi_no_na %>% 
  group_by(country) %>% 
  summarise(mean_index = mean(index),
            n = length(index))
```

`r emo::ji("clapper")` Add columns for the standard deviation and the standard error ($S.E. = \frac{s.d.}{\sqrt{n}}$) to the `hdi_summary` dataframe. It will look like this:

```{r task-1-summarise-3}
hdi_summary <- hdi_no_na %>% 
  group_by(country) %>% 
  summarise(mean_index = mean(index),
            n = length(index),
            sd_index = sd(index),
            se_index = sd_index/sqrt(n))

hdi_summary
```

We could filter the summary to get just the ten countries with the lowest mean HDI using:
```{r task-1-filter-2, echo=TRUE}
hdi_summary_low <- hdi_summary %>% 
  filter(rank(mean_index) < 11)

hdi_summary_low
```
And then plot them with:
```{r task-1-plot, echo=TRUE}
hdi_summary_low %>% 
  ggplot() +
  geom_point(aes(x = country,
                 y = mean_index)) +
  geom_errorbar(aes(x = country,
                    ymin = mean_index - se_index,
                    ymax = mean_index + se_index)) +
  scale_y_continuous(limits = c(0, 0.5),
                     expand = c(0, 0),
                     name = "HDI") +
  scale_x_discrete(expand = c(0, 0),
                   name = "") +
  theme_classic() +
  coord_flip()
```

`r emo::ji("clapper")` Build a pipeline that takes the `hdi` dataframe (the one with `r dim(hdi)[1]` rows) through to the plot above, without creating any intermediate data structures.

```{r task-1-pipeline, include=FALSE}
hdi %>%  
  filter(!is.na(index)) %>% 
  group_by(country) %>% 
  summarise(mean_index = mean(index),
            se_index = sd(index)/sqrt(length(index))) %>% 
  filter(rank(mean_index) < 11) %>% 
  ggplot() +
  geom_point(aes(x = country,
                 y = mean_index)) +
  geom_errorbar(aes(x = country,
                    ymin = mean_index - se_index,
                    ymax = mean_index + se_index)) +
  scale_y_continuous(limits = c(0, 0.5),
                     expand = c(0, 0),
                     name = "HDI") +
  scale_x_discrete(expand = c(0, 0),
                   name = "") +
  theme_classic() +
  coord_flip()
  
```

`r emo::ji("clapper")` Reconsider the organisation of your code and project.

-  Are the names of R objects, files and directories informative and systematic?
-  Have you scripted everything?
-  Is your code well commented? 
-  Is code in logical places?
-  See chapters 1 and 2 of [The tidyverse style guide](https://style.tidyverse.org/) for more suggestions.  

`r emo::ji("clapper")` Have a look at my version of [BIO00058M-HDI-w02](https://github.com/3mmaRand/BIO00058M-HDI-w02)



# Task 2 
These data are from a buoy (buoy #44025) off the coast of New Jersey: [buoy data](http://www.ndbc.noaa.gov/view_text_file.php?filename=44025h2011.txt.gz&dir=data/historical/stdmet/).

The organisation and format of data in a file is not always obvious to us. In these cases, it is useful to read the first few lines of the file to determine to best approach for importing it.

You can use the `readLines()` function to read the first few lines from the file:
```{r task-2-examine, echo= TRUE}
file <- "http://www.ndbc.noaa.gov/view_text_file.php?filename=44025h2011.txt.gz&dir=data/historical/stdmet/"
readLines(file, n = 3)
```

`readLines()` just shows what the first three (in this case) line of the file look like, it doesn't try to put it in a data structure such as a dataframe. This means it does not throw errors.

In the buoy data, the first line gives the column name, the second line gives units and the data themselves begin on line 3. In other words, the column names are over two lines. The best approach is to import the data without the column names then process the first two line to create comnplete column names.

Import the data without names:

```{r task-2-import, echo= TRUE}
buoy44025 <- read_table(file, 
                        col_names = FALSE,
                        skip = 2)
```

`r emo::ji("clapper")` Use `scan()` to read in the appropriate lines then tidy the results and name the columns `measure_units`. Hint 1: Look up `scan()` using `?scan`. Hint 2. The functions I used were `str_remove()`, `str_replace()` and `paste()`.
```{r task-2-colnames}
# read in the variable names from the first line, removing the hash
measure <- scan(file, 
                nlines = 1,
                what = character()) %>%
  str_remove("#")
# read in the units from the second line, removing the hash and
# replacing the / with _per_ as / is a special character
units <- scan(file, 
              skip = 1,
              nlines = 1, 
              what = character()) %>% 
  str_remove("#") %>% 
  str_replace("/", "_per_")
# paste the variable name and its units together for the column names
names(buoy44025) <- paste(measure, units, sep = "_") 
``` 
You are aiming for the names to look like this:
```{r echo=TRUE}
names(buoy44025)
```

# Task 3
In this task you will continue working with proteomic data from five immortalised mesenchymal stromal cell (MSC) lines.  [Y101_Y102_Y201_Y202_Y101-5.csv](../data-raw/Y101_Y102_Y201_Y202_Y101-5.csv)

`r emo::ji("clapper")` During the independent study you should have created a RStudio Project for all the examples the slides. I suggest you now start a new Project just for the case study and transfer the code your wrote for that example to the project. During the independent study you should have:   

-  imported the data
-  filtered out the bovine proteins and those proteins identified from fewer than 2 peptides
-  Extracted the genename from the description and put it in a column.


```{r task-3-import}
# define file name
filesol <- "../data-raw/Y101_Y102_Y201_Y202_Y101-5.csv"

# skip first two lines
sol <- read_csv(filesol, skip = 2) %>% 
  janitor::clean_names()

```

```{r task-3-filter}
# filter out the bovine proteins and those proteins identified from fewer than 2 peptides
sol <- sol %>% 
  filter(str_detect(description, "OS=Homo sapiens")) %>% 
  filter(x1pep == "x")
```

```{r task-3-extract-genename}
# Extract the genename from the description and put it in a column.
sol <- sol %>%
  mutate(genename =  str_extract(description,"GN=[^\\s]+") %>% 
           str_replace("GN=", ""))
```

`r emo::ji("clapper")` Extract the top protein identifier from the `accession` column and put it in a column called `protid`. The top protein identifier is the first Uniprot ID after the "1::" in the `accession` column. I recommend using the problem solving approach given in the slides: Start with one value and perform operations one at a time until you've worked out the pipeline. Then implement on the entire column.

You need to:

-  get one value from accession to practice with
-  find `1::` in the accession
-  extract the string that starts `1::` and ends with `;`
-  remove the `1::` part of that that string

```{r task-3-extract-protid}
# trying it out on one value
accession <- sol$accession[2]
protid <- str_extract(accession, "1::[^;]+") %>% 
  str_replace("1::", "")

# adding a new column 
sol <- sol %>%
  mutate(protid =  str_extract(accession, "1::[^;]+") %>% 
           str_replace("1::", ""))
```

`r emo::ji("clapper")` Create a second dataframe, `sol2` in which the protein abundances are in a single column, `abundance` and the cell lineage and replicate, `lineage_rep`, is indicated in another. All the other variables should also be in the new data frame. 
```{r task-3-pivot}
sol2 <- sol %>% pivot_longer(names_to = "lineage_rep",
                             values_to = "abundance",
                             cols = starts_with("y"))


```

`r emo::ji("clapper")` Create separate columns in `sol2` for the cell lineage and the replicate.
```{r task-3-extract-cols}
sol2 <- sol2 %>%
  extract(lineage_rep,
          c("line", "rep"),
          "(y[0-9]{3,4})\\_([a-c])")
```

`r emo::ji("clapper")` Write `sol2` to file
```{r task-3-write}
file <-  "../data-processed/sol2.txt"
write.table(sol2, 
            file, 
            quote = FALSE,
            row.names = FALSE)
```


# The code files
These contain all the code needed in the workshop even where it is not visible on the webpage.
[Rmd file](02_tidying_data.Rmd) The Rmd file is the file I use to compile the practical. Rmd stands for R markdown. It allows R code and ordinary text to be interweaved to produce well-formatted reports including webpages. If you right-click on the link and choose Save-As, you will be able to open the Rmd file in RStudio. Alternatively, [View in Browser](https://github.com/3mmaRand/BIO00058M-Data-science-2020/blob/master/workshops/02_tidying_data.Rmd).


Pages made with `rmarkdown` `r Cite(myBib, c("markdown1","markdown2", "markdown3"))`, `RefManageR``r Cite(myBib, "RefManageR")` 


# References 

```{r refs, echo=FALSE, results="asis"}
PrintBibliography(myBib)  
```

# Please cite as:

Emma Rand. (2021). Data Science strand of BIO00058M (v1.0). Zenodo. https://doi.org/10.5281/zenodo.5442490

![](../pics/58Mend.png)


